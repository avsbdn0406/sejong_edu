{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "311e06bf-a020-457f-8721-81b7c754ca40",
   "metadata": {},
   "source": [
    "# 08장 SVM (Support Vector Machine)\n",
    "---\n",
    "- Dates : Sep 04, 2024  \n",
    "- Author : JaeEun Yoo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e871c-ef32-4536-9117-9b83de3fb495",
   "metadata": {},
   "source": [
    "## SVM(Support Vector Machine)이란?\n",
    "- 서포트 벡터 머신(이하 SVM)은 결정 경계(Decision Boundary), 즉 분류를 위한 기준 선을 정의하는 모델\n",
    "- 분류되지 않은 새로운 점이 나타나면 어느 쪽에 속하는지 확인하여 분류 과제를 수행\n",
    "- 두 클래스로부터 최대한 멀리 떨어져 있는(즉 확실하게 클래스가 나뉘는) 결정 경계를 찾는 분류기로, 특정 조건을 만족하는 동시에 클래스를 분류하는 것을 목표로 함\n",
    "- 결정 경계를 통해 어느 쪽에 속하는지 판단하는 것으로, 선형이나 비선형 분류, 회귀, 이상치 탐색에도 사용할 수 있는 강력한 성능을 갖는 지도 학습 모델\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70b5ef-662b-40e9-8b15-9b1fae126657",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4122e19-8ab5-4e88-9047-82005bc78d43",
   "metadata": {},
   "source": [
    "## 결정경계(Decision Boundary)란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd46ef0-0960-420c-a5f6-302156bec4c2",
   "metadata": {},
   "source": [
    "- 두 데이터 분포를 완벽하게 나누는 선, 즉 결정 경계는 무수히 많이 존재할 수 있음\n",
    "- 두 데이터 분포를 가장 정확하게 분류할 수 있는 단 하나의 결정 경계를 선택해야하며, 이를 최적의 Decision Boundary(최적의 결정경계)라고 함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e3e1b-742a-42e5-aeed-4ed1cf898a6c",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813c9d6-7651-495c-9f5e-b8624794677a",
   "metadata": {},
   "source": [
    "- Graph C : 선이 파란색 부류와 너무 가까워서 아슬아슬\u001f\n",
    "- Graph F : 두 클래스(분류) 사이에서 거리가 가장 멈\n",
    "- 결정 경계는 **데이터 군으로부터 최대한 멀리 떨어지는 게 최적임**\n",
    "- 서포트 벡터 머신(Support Vector Machine)이라는 이름에서 **Support Vectors는 결정 경계와 가까이 있는 데이터 포인트**들을 의미함\n",
    "- 이 데이터들이 경계를 정의하는 결정적인 역할을 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbdfa3f-f87e-4008-b15b-9ba3e7518e33",
   "metadata": {},
   "source": [
    "## SVM의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fd1db8-8f6a-44c2-b0b2-6c5fcae1c8ac",
   "metadata": {},
   "source": [
    "### Margin이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0970a3-7c9b-466d-8a28-919ea37e3422",
   "metadata": {},
   "source": [
    "- 마진(Margin)은 **결정 경계와 서포트 벡터 사이의 거리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b1ef61-ab58-4727-999a-4083d5c6b32b",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176fd65a-8071-4bb4-8e46-9771cd21405e",
   "metadata": {},
   "source": [
    "- 가운데 실선이 '결정 경계'\n",
    "- 실선으로부터 검은 테두리가 있는 빨간점 1개, 파란점 2개까지 영역을 두고 점선을 그여졌으므로, 해당 점은 '서포트 벡터'\n",
    "- 점선으로부터 결정 경계까지의 거리가 바로 '마진(Margin)'\n",
    "- 결정 경계를 기준으로 서포트 벡터의 거리가 멀 수록 최적의 결정경계이다 -->  **마진을 최대화해야한다.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e8995-59c3-4bd8-8774-99a18397224b",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781526eb-7b24-4a3a-81b8-808e3f9beba2",
   "metadata": {},
   "source": [
    "* Cluster : 데이터가 모여있는 집합 또는 데이터군\n",
    "* Decision boundry (Separating line 또는 Classifier) : 결정 경계\n",
    "* Support Vectors : 결정 경계에서 가장 가까운 데이터 점\n",
    "* Margin : 결정 경계로부터 Support Vectors 까지의 거리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c99db6b-0a97-45bd-ba7d-88ce2643591a",
   "metadata": {},
   "source": [
    "> **SVM의 장점!**\n",
    "- SVM에서는 결정 경계를 정의하는 게 결국 서포트 벡터이기 때문에 데이터 포인트 중에서 **서포트 벡터만 잘 골라내면** 나머지 쓸 데 없는 수많은 데이터 포인트들을 무시할 수 있다 ->  **빠르다!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddacffa3-3ca9-496f-aa3b-be8a87967b90",
   "metadata": {},
   "source": [
    "---\n",
    "## SVM의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b9b00-a142-49b5-bd46-fb52c0ecf229",
   "metadata": {},
   "source": [
    "### Hard margin vs Soft margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0298954-0b1b-4f89-b596-9c79d34e4797",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c0dcb-6182-47e9-9723-098926330488",
   "metadata": {},
   "source": [
    "- Hard margin 분류 : 모든 샘플이 도로 바깥쪽에 분류됨 (좌)\n",
    "- Hard margin분류는 훈련 세트가 선형적으로 구분되는 경우에만 가능하며 이상치에 매우 민감함\n",
    "- e.g.) 파란색 클래스에 빨간색 데이터가 섞여 있어 하드 마진을 찾을 수 없게 되거나, 데이터 이상치로 인한 일반화가 되지 않을 수 있음\n",
    "- **실제로 하드 마진이 가능한 데이터 분류는 거의 없음**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e123cb-cc8a-4fbd-806f-2c07b91f3ea7",
   "metadata": {},
   "source": [
    "- Soft margin 분류 : 마진을 가능한 한 넓게 유지하며 마진 오류를 발생시키지 않는 적절한 균형을 잡도록 분류됨 (우)\n",
    "- 마진폭을 가능한한 넓게 유지하면서 이상치가 발생하더라도 어느 정도 허용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba09e9-e07b-47a9-9715-8c4f1bd08d68",
   "metadata": {},
   "source": [
    "## Soft Margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec1856-a049-4ba4-8f75-e70bf9b5e605",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b0cd64-c341-482f-9d8a-00e8ecd1157d",
   "metadata": {},
   "source": [
    "- **Soft Margin은 SVM에서 Margin은 최대화 하면서 약간의 오류를 허용하는 방법**\n",
    "- Soft Margin의 핵심 아이디어\n",
    "1) **마진 최대화**  \n",
    "* 결정 경계에서 가장 가까운 데이터(Supprot Vectors)와 결정 경계 사이의 거리를 최대화\n",
    "2) **약간의 Error 허용**  \n",
    "* 일부 데이터는 경계를 넘어서거나 마진 내에 위치할 수 있으며, 이를 통해 모델이 더 유연하게 데이터에 적응할 수 있게 한다.\n",
    "\n",
    "위의 두가지 아이디어를 충족시키기 위해 SVM에서는 **“C”라고 불리는 penalty parameter를 사용함**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6b7f0-7ec3-45d4-b484-6b5f6653f737",
   "metadata": {},
   "source": [
    "### C pararmeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb83f5-94aa-4ce9-bb90-2376b09aefdd",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d45c7-0820-4be7-a649-6d360c9e71e0",
   "metadata": {},
   "source": [
    "**C값이 클수록**\n",
    "- Hard margin(Error 허용 안 함), 오류를 거의 허용하지 않음\n",
    "- 모델은 데이터를 최대한 올바르게 분류하려고 하기 때문에 margin은 작아지고 overfitting(과적합)의 위험이 발생\n",
    "\n",
    "**C값이 작을수록**\n",
    "- Soft margin(Error를 허용함). 비교적 더 많은 오류를 허용함\n",
    "- 모델은 margin을 최대화 하면서 일부 데이터가 잘못 분류되는 것을 허용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9824e034-4a5b-4b3f-ae79-f1afb0d762e9",
   "metadata": {},
   "source": [
    "---\n",
    "## Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4972bc9-0a97-41db-aba2-9fbf3530c21b",
   "metadata": {},
   "source": [
    "- SVM의 기본 아이디어는 데이터를 고차원 공간으로 매핑하여 선형적으로 분리할 수 있는 초평면을 찾는 것\n",
    "- 앞서 설명한 것들은 모두 Linear하게 분리가 가능한 데이터셋이였지만 만약 선형으로 분리 할 수 없는 데이터셋이 있다면?\n",
    "\n",
    "<br>  \n",
    "  \n",
    "- **Kernel**은 데이터를 현재 차원보다 더 높은 차원으로 매핑하여 선형적으로 분리 가능하게 만드는 함수\n",
    "- Kernel 함수는 두 벡터의 내적을 계산하여 새로운 고차원 공간으로 변환된 결과를 나타내는데, 이를 통해 비선형적인 데이터도 선형적으로 분리할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376ba90-bb4a-4d05-a7ed-c3e79aeb09e6",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf00a2f-d60d-476a-a99f-8540fb78939c",
   "metadata": {},
   "source": [
    "- 위와같은 데이터는 어떤식으로도 선형으로는 분류할 수 없는 데이터\n",
    "- SVM을 적용하기 위해 Kernel을 활용하여 2차원 데이터를 3차원 데이터로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99460227-a394-4157-9c50-ea7ea52ff068",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c34d42-467f-4024-928f-27d4bbac861e",
   "metadata": {},
   "source": [
    "- 2차원 데이터를 3차원 데이터로 변경한 뒤 데이터군을 분리할 수 있는 초평면을 구성함으로써 SVM을 사용할 수 있음\n",
    "- 그러나 저차원 데이터를 분류하기 위해 고차원 데이터 형태로 실제 변환하는 작업은 효율적이지 못함\n",
    "- SVM에서는 이러한 고차원 공간으로의 변환 작업을 직접 수행하지 않고 효율적으로 계산할 수 있는 **Kernel Trick**을 제시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f287d1-6d3a-4ea2-b71d-d2b1bdad22f4",
   "metadata": {},
   "source": [
    "### Kernel Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb27f3-195d-418d-922a-5540c8c22e27",
   "metadata": {},
   "source": [
    "- 데이터를 명시적으로 고차원 공간으로 변환하지 않고, Kernel 함수를 통해 변환된 고차원 공간에서의 내적을 효율적으로 계산하는 방법\n",
    "- Kernel Trick을 사용하면 계산 비용을 크게 줄이면서도 고차원 공간에서의 분리를 가능하게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbbe7b-c491-4bdf-bec8-6d9bf50ab2c0",
   "metadata": {},
   "source": [
    "1) Linear kernel : 원래 공간에서 선형 분리를 수행\n",
    "2) Polynomial kernel : 입력 벡터의 다항식 형태로 매핑\n",
    "3) **RBF kernel (=Gaussian kernel)** : 가우시안 커널이라고도 하며, 무한 차원 공간으로 매핑\n",
    "4) Sigmoid kernel :신경망에서 사용하는 활성화 함수와 유사한 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524df49-5f7e-47b8-9fb5-b3424bb5d613",
   "metadata": {},
   "source": [
    "### RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a203a-2c9d-4c4f-9e5f-67957c0aec9e",
   "metadata": {},
   "source": [
    "- kernel 함수 중 Default로 지정되어 가장 많이 사용되는 함수\n",
    "- 두 데이터 포인트 x와 y 사이의 거리에 기초하여 다음과 같이 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea527da9-efa6-4d1f-980d-1ad6c680e6af",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4088e61-53ea-4e4c-a94c-6b483c78e0b4",
   "metadata": {},
   "source": [
    "- ∥x−y∥ : 두 벡터 x와 y 사이의 유클리드 거리\n",
    "- γ : 커널의 폭을 조절하는 매개변수로 사용 (반드시 양수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34125b46-a39d-4c8e-bd6e-a32823003de2",
   "metadata": {},
   "source": [
    " - γ(gamma)는 데이터 포인트 사이의 유사성을 측정하는데 사용됨\n",
    "- 쉽게 표현하면 **결정 경계를 얼마나 유연하게 그을지 정해주는 매개변수**\n",
    "- 학습 데이터에 얼마나 민감하게 반응할 것인지 모델을 조정하는 것이므로 SVM의 C파라미터와 비슷함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810bbb57-ecef-47f6-ae8b-b22c8a043d91",
   "metadata": {},
   "source": [
    "![numpy array 01](./figures/svm_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a56327-7951-4794-946d-c96529d904f8",
   "metadata": {},
   "source": [
    "---\n",
    "## 실습 : 붓꽃 데이터 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac43617-5b1e-4973-a936-d16c775630b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075c163-be9f-4ccb-bb32-9f7bb780e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터셋 생성\n",
    "# iris 데이터셋을 사용합니다.\n",
    "iris = datasets.load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4d218-0f19-4ff7-8717-d045aeece3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f39bb2f-d7c1-42bf-acff-e8f832eb2944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d55ff1-10f9-452e-bc8e-1033a4b35b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b9e75-7342-4d2e-9db4-2cc3cff14345",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3fc5ed-aa40-45b0-8651-2d59395be0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]  # 꽃잎 길이와 폭만 사용\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5fca20-90b0-4dae-b2e2-1818a679dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e4d3e-d522-44c7-ad48-2cf664df6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a50789-6f2c-40e5-bb22-9190edf2c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터셋을 훈련 세트와 테스트 세트로 나눔\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed10497-7b51-4729-842d-ec31d1bfc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SVM 모델 생성 및 학습 (RBF 커널 사용)\n",
    "model = svm.SVC(kernel='rbf', gamma='scale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6971c736-2843-4f03-a714-9422370107f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7addf-55cf-4c84-91af-1e3ab06cb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 모델 성능 평가\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba0114-75f5-46e0-bbc8-48d2e7269fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터와 결정 경계 시각화\n",
    "def plot_decision_boundary(X, y, model):\n",
    "    h = .02  # 결정 경계의 해상도\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.title('SVM with RBF Kernel')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d0c7a-2720-4801-a495-3f9d59ce8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정 경계 시각화\n",
    "plot_decision_boundary(X_train, y_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4284e-aa50-40be-8b46-ac0e00f528df",
   "metadata": {},
   "source": [
    ">refer\n",
    "- https://velog.io/@jjw9599/Support-Vector-Machine01\n",
    "- https://idkim97.github.io/machine%20learning/MachineLearning_SVM/\n",
    "- https://velog.io/@hyesoup/%EC%84%9C%ED%8F%AC%ED%8A%B8-%EB%B2%A1%ED%84%B0-%EB%A8%B8%EC%8B%A0Support-Vector-Macine-SVM\n",
    "- https://ittrue.tistory.com/44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ad831-96d6-46b9-ada0-f0a0f7e7b8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
